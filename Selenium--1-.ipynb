{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver= webdriver.Chrome(r\"C:\\Users\\Rajeev\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting url\n",
    "url=\"https://www.naukri.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter Data Analyst in search title\n",
    "search= driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter Bangalore in location search\n",
    "loc= driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "loc.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on search button\n",
    "Search_btn= driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section/div/form/div[3]/button\")  # Absolute xpath\n",
    "Search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist / Data Analyst -Business Analyst',\n",
       " 'Assistant Vice President - MIS & Reporting ( Business Data Analyst)',\n",
       " 'Network Design & Data Analyst',\n",
       " 'Business Data Analyst - MIS & Reporting',\n",
       " 'Data analysts',\n",
       " 'Excel VBA Jobs Bangalore | VBA data analyst Jobs',\n",
       " 'Software Developer / Web Developer/data analyst',\n",
       " 'Consultant - Data Analyst',\n",
       " 'Data Analyst – Financial, Healthcare, Sports Betting',\n",
       " 'Data Analyst Azure',\n",
       " 'Urgently Looking For Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Senior Security Specialist - CS Awareness & Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Senior Data Analyst Python, ML - Bangalore',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Senior Data Analyst',\n",
       " 'Consultant - Data Analyst',\n",
       " 'Data Analyst']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetching job titles\n",
    "job_title_tags= driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")  # Relative xpath\n",
    "job_title=[]\n",
    "for i in job_title_tags:\n",
    "    job_title.append(i.text)   # Extracting text\n",
    "job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hyderabad/Secunderabad, Chennai, Bangalore/Bengaluru',\n",
       " 'Mumbai, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Mumbai, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Coimbatore, Bangalore/Bengaluru, Trivandrum/Thiruvananthapuram',\n",
       " 'Hyderabad/Secunderabad, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Pune, Chennai, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru, Bangalore',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru(2nd Phase JP Nagar)',\n",
       " 'Bangalore/Bengaluru(Whitefield)',\n",
       " '(WFH during Covid)',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fetching job_locations\n",
    "loc_tags= driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span\")\n",
    "loc=[]\n",
    "for i in loc_tags:\n",
    "    loc.append(i.text)\n",
    "loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Inflexion Analytix Private Limited',\n",
       " 'INTERTRUSTVITEOS CORPORATE AND FUND SERVICES PVT. LTD.',\n",
       " 'Dell International Services India Private Limited',\n",
       " 'INTERTRUST GROUP',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'Mind Circus Innovation',\n",
       " 'Edubridgeindia',\n",
       " 'Flipkart Internet Private Limited',\n",
       " 'Quantsys',\n",
       " 'CONDUENT BUSINESS SERVICES INDIA LLP',\n",
       " 'Flipkart Internet Private Limited',\n",
       " 'Allegis Services India Pvt. Ltd.',\n",
       " 'Cognizant Technology Solutions India Pvt Ltd',\n",
       " 'Clarivate Analytics (TRCPL Projects Pvt Ltd.)',\n",
       " '2coms',\n",
       " 'Siemens Limited',\n",
       " 'Bright Money',\n",
       " 'Liventus, Inc.',\n",
       " 'ZapCom Solutions Pvt Ltd',\n",
       " 'ExecBoardinAsia']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetching company name\n",
    "company_tags= driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "company=[]\n",
    "for i in company_tags:\n",
    "    company.append(i.text)\n",
    "company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0-3 Yrs',\n",
       " '10-15 Yrs',\n",
       " '0-2 Yrs',\n",
       " '3-8 Yrs',\n",
       " '5-10 Yrs',\n",
       " '0-2 Yrs',\n",
       " '0-1 Yrs',\n",
       " '0-2 Yrs',\n",
       " '2-4 Yrs',\n",
       " '3-6 Yrs',\n",
       " '2-3 Yrs',\n",
       " '8-13 Yrs',\n",
       " '4-7 Yrs',\n",
       " '1-2 Yrs',\n",
       " '2-7 Yrs',\n",
       " '0-5 Yrs',\n",
       " '0-2 Yrs',\n",
       " '5-8 Yrs',\n",
       " '7-12 Yrs',\n",
       " '5-10 Yrs']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fetching Experience required\n",
    "exp_tags= driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']\")\n",
    "experience=[]\n",
    "for i in exp_tags:\n",
    "    experience.append(i.text)\n",
    "experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_Location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Hyderabad/Secunderabad, Chennai, Bangalore/Ben...</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Assistant Vice President - MIS &amp; Reporting ( B...</td>\n",
       "      <td>Mumbai, Bangalore/Bengaluru</td>\n",
       "      <td>INTERTRUSTVITEOS CORPORATE AND FUND SERVICES P...</td>\n",
       "      <td>10-15 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Network Design &amp; Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Dell International Services India Private Limited</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Business Data Analyst - MIS &amp; Reporting</td>\n",
       "      <td>Mumbai, Bangalore/Bengaluru</td>\n",
       "      <td>INTERTRUST GROUP</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data analysts</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Excel VBA Jobs Bangalore | VBA data analyst Jobs</td>\n",
       "      <td>Coimbatore, Bangalore/Bengaluru, Trivandrum/Th...</td>\n",
       "      <td>Mind Circus Innovation</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Software Developer / Web Developer/data analyst</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru</td>\n",
       "      <td>Edubridgeindia</td>\n",
       "      <td>0-1 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Consultant - Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst – Financial, Healthcare, Sports B...</td>\n",
       "      <td>Pune, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>Quantsys</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst Azure</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>CONDUENT BUSINESS SERVICES INDIA LLP</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1  Assistant Vice President - MIS & Reporting ( B...   \n",
       "2                      Network Design & Data Analyst   \n",
       "3            Business Data Analyst - MIS & Reporting   \n",
       "4                                      Data analysts   \n",
       "5   Excel VBA Jobs Bangalore | VBA data analyst Jobs   \n",
       "6    Software Developer / Web Developer/data analyst   \n",
       "7                          Consultant - Data Analyst   \n",
       "8  Data Analyst – Financial, Healthcare, Sports B...   \n",
       "9                                 Data Analyst Azure   \n",
       "\n",
       "                                        Job_Location  \\\n",
       "0  Hyderabad/Secunderabad, Chennai, Bangalore/Ben...   \n",
       "1                        Mumbai, Bangalore/Bengaluru   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                        Mumbai, Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5  Coimbatore, Bangalore/Bengaluru, Trivandrum/Th...   \n",
       "6        Hyderabad/Secunderabad, Bangalore/Bengaluru   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                 Pune, Chennai, Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                                        Company_name Experience  \n",
       "0                 Inflexion Analytix Private Limited    0-3 Yrs  \n",
       "1  INTERTRUSTVITEOS CORPORATE AND FUND SERVICES P...  10-15 Yrs  \n",
       "2  Dell International Services India Private Limited    0-2 Yrs  \n",
       "3                                   INTERTRUST GROUP    3-8 Yrs  \n",
       "4                             IBM India Pvt. Limited   5-10 Yrs  \n",
       "5                             Mind Circus Innovation    0-2 Yrs  \n",
       "6                                     Edubridgeindia    0-1 Yrs  \n",
       "7                  Flipkart Internet Private Limited    0-2 Yrs  \n",
       "8                                           Quantsys    2-4 Yrs  \n",
       "9               CONDUENT BUSINESS SERVICES INDIA LLP    3-6 Yrs  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Data Frame\n",
    "jobs= pd.DataFrame()\n",
    "jobs[\"Job_title\"]=job_title[:10]\n",
    "jobs[\"Job_Location\"]=loc[:10]\n",
    "jobs[\"Company_name\"]=company[:10]\n",
    "jobs[\"Experience\"]=experience[:10]\n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, full job-description. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting url\n",
    "url=\"https://www.naukri.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter Data Scientist in search title\n",
    "search= driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter Bangalore in location search\n",
    "loc= driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "loc.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on search button\n",
    "Search_btn= driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section/div/form/div[3]/button\")\n",
    "Search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist / Data Analyst -Business Analyst',\n",
       " 'Data Scientist: Advanced Analytics',\n",
       " 'Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Sr Data Scientist',\n",
       " 'EXL - Senior Data Scientist, 5+ yrs, Mumbai / PUNE / BLR / Chennai',\n",
       " 'Senior Data Scientist',\n",
       " 'Senior Data Scientist/ Tech Lead - SQL/ Python/ Big Data',\n",
       " 'Data Scientist']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetching job titles\n",
    "job_title_tags= driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "job_title=[]\n",
    "for i in job_title_tags:\n",
    "    job_title.append(i.text)\n",
    "job_title[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hyderabad/Secunderabad, Chennai, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Hyderabad/Secunderabad, Gurgaon/Gurugram, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Pune, Chennai, Bangalore/Bengaluru, Delhi / NCR',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Pune, Chennai, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fetching job_locations\n",
    "loc_tags= driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span\")\n",
    "loc=[]\n",
    "for i in loc_tags:\n",
    "    loc.append(i.text)\n",
    "loc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Inflexion Analytix Private Limited',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'inVentiv International Pharma Services Pvt. Ltd.',\n",
       " 'Superior Group',\n",
       " 'FabHotel Aay Kay Model Town',\n",
       " 'EXL Service',\n",
       " 'ORMAE (Operations Research Machine learning & Analytics Experts LLP)',\n",
       " 'Exploro Solutions',\n",
       " 'Center for Study of Science, Technology and Policy']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetching company name\n",
    "company_tags= driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "company=[]\n",
    "for i in company_tags:\n",
    "    company.append(i.text)\n",
    "company[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.naukri.com/job-listings-data-scientist-data-analyst-business-analyst-inflexion-analytix-private-limited-hyderabad-secunderabad-chennai-bangalore-bengaluru-0-to-3-years-020721003625?src=jobsearchDesk&sid=1625803334381425&xp=1&px=1',\n",
       " 'https://www.naukri.com/inflexion-analytix-jobs-careers-3958080',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-advanced-analytics-ibm-india-pvt-limited-bangalore-bengaluru-5-to-10-years-070721908032?src=jobsearchDesk&sid=1625803334381425&xp=2&px=1',\n",
       " 'https://www.naukri.com/ibm-india-jobs-careers-16987',\n",
       " 'https://www.ambitionbox.com/reviews/ibm-reviews?utm_campaign=srp_ratings&utm_medium=desktop&utm_source=naukri?utm_campaign=srp_ratings&utm_medium=desktop&utm_source=naukri?utm_campaign=srp_ratings&utm_medium=desktop&utm_source=naukri',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-ibm-india-pvt-limited-bangalore-bengaluru-3-to-6-years-080721906014?src=jobsearchDesk&sid=1625803334381425&xp=3&px=1',\n",
       " 'https://www.naukri.com/ibm-india-jobs-careers-16987',\n",
       " 'https://www.ambitionbox.com/reviews/ibm-reviews?utm_campaign=srp_ratings&utm_medium=desktop&utm_source=naukri?utm_campaign=srp_ratings&utm_medium=desktop&utm_source=naukri?utm_campaign=srp_ratings&utm_medium=desktop&utm_source=naukri',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-inventiv-international-pharma-services-pvt-ltd-hyderabad-secunderabad-gurgaon-gurugram-bangalore-bengaluru-3-to-6-years-090721000064?src=jobsearchDesk&sid=1625803334381425&xp=4&px=1',\n",
       " 'https://www.naukri.com/inventiv-international-pharma-services-jobs-careers-835939']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetching job titles\n",
    "job_title_tags= driver.find_elements_by_xpath(\"//div[@class='info fleft']//a\")\n",
    "job_url=[]\n",
    "job_desc=[]\n",
    "for i in job_title_tags:\n",
    "    job_url.append(i.get_attribute(\"href\"))\n",
    "job_url[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Job description  Job Role: Data Scientist/Data Analyst /Business Analyst  Location: Chennai/Bangalore/Hyderabad  Greetings from CAIA - Center for Artificial Intelligence & Advanced Analytics 43% of companies experienced a high deficit of skilled resources with Advanced Analytical skills and AI implementing capabilities in the year 2020. CAIA gives you a great opportunity to enter the world of future technologies and Innovations- Data Science, Analytics, AI, Data Visualization, and Cloud Computing.  While 2020 was a year like no other, we are living in an interesting times where data is reshaping the world, and businesses are rapidly adopting technology to gain an edge over others. Hence, there's a substantial increase in demand for technology professionals who can implement systems in data science, machine learning, and AI in Tier 1 and Tier 2 organizations working closely with us.  To help you build a sustainable career we would like you to utilize data, software and Analytical approaches in Data Science and AI to upskill and get recruited into an organization appreciating your skilling journey. Applications invited from all Freshers and experienced candidates (0-3 yrs) aspiring to make a career in Artificial Intelligence and Advanced Analytics and Data Science. If you wish to make a shift in your career or undergo a career transition, upskilling is essential since it allows you to learn more about the domain and acquire the required skills.  Call to schedule interview Monday -Saturday from 10:00 am to 7 Pm  Koodesh B- +91 73395 11107 Manigandan B - +91 93444 57360  Email :  careerguidance.koodes@centerforaia.com manigandan@centerforaia.com  What is needed from you? Freshers who wish to start their career in Analytics and AI and professionals who wish to upskill or change their domain to analytics and emerging technologies are free to apply. Educational background in any one of the following- BE/B.Tech, ME/M Tech, MSc, BSc/MSc Math's and Statistics, B Com, BCA, BSc CS, BSC IT, MSC IT, MCA Skills relating to Mathematics/Statistics. Natural passion towards numbers, business, coding, Analytics, and Artificial Intelligence, Machine Learning, visualization Good verbal and written communication skills Ability to understand domains in businesses across various sectors  Selection procedure includes Aptitude Test & Communication Exam - Online / Offline SQL/Python test - Online / Offline Candidates who clear the above will have one-one discussions with our Career Guidance Manager for further evaluation and processing of your Resume.  All the Shortlisted candidates will be eligible to continue the corporate training with CAIA What you can expect from us?  You will get trained on the following modules for a period of 12-14 weeks: SQL & PLSQL Data Wrangling using Python Data Visualization Using Power-BI Statistics for Machine Learning Artificial Intelligence, Data Interpretation Supervised & Unsupervised Learning, NLP & Deep Learning Cloud Data Lake Business intelligence & Data Visualization Simulation Projects Expected Outcome?  At the end of the Training you are expected to be well versed with the following: Analysis of large and complex data sets from multiple sources Development and evaluation of data analytics models, algorithms, and solutions Understanding/implementation of ML algorithms, performance tuning, and reporting Implementation of algorithms to mine targeted data and the ability to convert data into a business story Translation of business requirements into technical requirements; Data extraction, preparation, and transformation Identification, development, and implementation of statistical techniques and algorithms that address business challenges and adds value to the organization Requirement Analysis and communication of findings in the form of a meaningful story with the stakeholders Finding analytical solutions to abstract business issues. Apply objective analysis of facts before coming to a conclusion\"]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping job description data\n",
    "for i in job_url[:10]:\n",
    "    driver.get(i)\n",
    "    job_desc_tags= driver.find_elements_by_xpath(\"//div[@class='dang-inner-html']\")\n",
    "    for j in job_desc_tags:\n",
    "        job_desc.append(j.text.replace(\"\\n\",\" \"))\n",
    "job_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3: scrape data using the filters available on the webpage as shown below:\n",
    "#### You have to use the location and salary filter.\n",
    "#### You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "#### You have to scrape the job-title, job-location, company_name, experience_required.\n",
    "#### The location filter to be used is “Delhi/NCR”\n",
    "#### The salary filter to be used is “3-6” lakhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first get the webpage https://www.naukri.com/\n",
    "url=\"https://www.naukri.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter “Data Scientist” in “Skill,Designations,Companies” field\n",
    "search= driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on search button\n",
    "Search_btn= driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section/div/form/div[3]/button\")\n",
    "Search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then apply the location filter and salary filter by checking the respective boxes\n",
    "loc= driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[3]/div[2]/div[3]/label/i\")\n",
    "loc.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary= driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[4]/div[2]/div[2]/label/i\")\n",
    "salary.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist/Data Analyst /Business Analyst',\n",
       " 'Senior Data Scientist',\n",
       " 'Only Fresher / Data Scientist / Data Analyst / Analytics - MNC Jobs',\n",
       " 'Advanced Analytics -Data Scientist',\n",
       " 'Data Scientist (Early Joiner)',\n",
       " 'Data Scientist - Machine Learning/ NLP',\n",
       " 'Data Scientist || Python || C2H',\n",
       " 'Data Scientist || Python || C2H',\n",
       " 'Chaayos is Looking For Data Scientist',\n",
       " 'Data Scientist']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetching job titles\n",
    "job_title_tags= driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "job_title=[]\n",
    "for i in job_title_tags:\n",
    "    job_title.append(i.text)\n",
    "job_title[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pune, Delhi / NCR, Mumbai (All Areas)',\n",
       " 'Hyderabad/Secunderabad, Gurgaon/Gurugram, Bangalore/Bengaluru',\n",
       " 'Noida, Greater Noida, Delhi / NCR',\n",
       " 'New Delhi, Hyderabad/Secunderabad',\n",
       " 'Noida(Sector-59 Noida)',\n",
       " 'Gurgaon/Gurugram',\n",
       " 'Noida, Kolkata, Gurgaon/Gurugram, Bangalore/Bengaluru',\n",
       " 'Noida, Kolkata, Gurgaon/Gurugram, Bangalore/Bengaluru',\n",
       " 'New Delhi',\n",
       " 'Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fetching job_locations\n",
    "loc_tags= driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span\")\n",
    "loc=[]\n",
    "for i in loc_tags:\n",
    "    loc.append(i.text)\n",
    "loc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Inflexion Analytix Private Limited',\n",
       " 'inVentiv International Pharma Services Pvt. Ltd.',\n",
       " 'GABA Consultancy services',\n",
       " 'ERM Placement Services (P) Ltd.',\n",
       " 'R Systems International Ltd.',\n",
       " 'TalPro',\n",
       " 'Growel Softech Pvt. Ltd.',\n",
       " 'Growel Softech Pvt. Ltd.',\n",
       " 'Chaayos (Sunshine Teahouse Pvt. Ltd.)',\n",
       " 'Fractal Analytics']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetching company name\n",
    "company_tags= driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "company=[]\n",
    "for i in company_tags:\n",
    "    company.append(i.text)\n",
    "company[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0-3 Yrs',\n",
       " '3-6 Yrs',\n",
       " '0-0 Yrs',\n",
       " '3-7 Yrs',\n",
       " '4-8 Yrs',\n",
       " '2-6 Yrs',\n",
       " '4-6 Yrs',\n",
       " '4-6 Yrs',\n",
       " '0-5 Yrs',\n",
       " '3-7 Yrs']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fetching Experience required\n",
    "exp_tags= driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']\")\n",
    "experience=[]\n",
    "for i in exp_tags:\n",
    "    experience.append(i.text)\n",
    "experience[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_Location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist/Data Analyst /Business Analyst</td>\n",
       "      <td>Pune, Delhi / NCR, Mumbai (All Areas)</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Hyderabad/Secunderabad, Gurgaon/Gurugram, Bang...</td>\n",
       "      <td>inVentiv International Pharma Services Pvt. Ltd.</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Only Fresher / Data Scientist / Data Analyst /...</td>\n",
       "      <td>Noida, Greater Noida, Delhi / NCR</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Advanced Analytics -Data Scientist</td>\n",
       "      <td>New Delhi, Hyderabad/Secunderabad</td>\n",
       "      <td>ERM Placement Services (P) Ltd.</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist (Early Joiner)</td>\n",
       "      <td>Noida(Sector-59 Noida)</td>\n",
       "      <td>R Systems International Ltd.</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - Machine Learning/ NLP</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>TalPro</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist || Python || C2H</td>\n",
       "      <td>Noida, Kolkata, Gurgaon/Gurugram, Bangalore/Be...</td>\n",
       "      <td>Growel Softech Pvt. Ltd.</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist || Python || C2H</td>\n",
       "      <td>Noida, Kolkata, Gurgaon/Gurugram, Bangalore/Be...</td>\n",
       "      <td>Growel Softech Pvt. Ltd.</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chaayos is Looking For Data Scientist</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Chaayos (Sunshine Teahouse Pvt. Ltd.)</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0      Data Scientist/Data Analyst /Business Analyst   \n",
       "1                              Senior Data Scientist   \n",
       "2  Only Fresher / Data Scientist / Data Analyst /...   \n",
       "3                 Advanced Analytics -Data Scientist   \n",
       "4                      Data Scientist (Early Joiner)   \n",
       "5             Data Scientist - Machine Learning/ NLP   \n",
       "6                    Data Scientist || Python || C2H   \n",
       "7                    Data Scientist || Python || C2H   \n",
       "8              Chaayos is Looking For Data Scientist   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                        Job_Location  \\\n",
       "0              Pune, Delhi / NCR, Mumbai (All Areas)   \n",
       "1  Hyderabad/Secunderabad, Gurgaon/Gurugram, Bang...   \n",
       "2                  Noida, Greater Noida, Delhi / NCR   \n",
       "3                  New Delhi, Hyderabad/Secunderabad   \n",
       "4                             Noida(Sector-59 Noida)   \n",
       "5                                   Gurgaon/Gurugram   \n",
       "6  Noida, Kolkata, Gurgaon/Gurugram, Bangalore/Be...   \n",
       "7  Noida, Kolkata, Gurgaon/Gurugram, Bangalore/Be...   \n",
       "8                                          New Delhi   \n",
       "9      Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "\n",
       "                                       Company_name Experience  \n",
       "0                Inflexion Analytix Private Limited    0-3 Yrs  \n",
       "1  inVentiv International Pharma Services Pvt. Ltd.    3-6 Yrs  \n",
       "2                         GABA Consultancy services    0-0 Yrs  \n",
       "3                   ERM Placement Services (P) Ltd.    3-7 Yrs  \n",
       "4                      R Systems International Ltd.    4-8 Yrs  \n",
       "5                                            TalPro    2-6 Yrs  \n",
       "6                          Growel Softech Pvt. Ltd.    4-6 Yrs  \n",
       "7                          Growel Softech Pvt. Ltd.    4-6 Yrs  \n",
       "8             Chaayos (Sunshine Teahouse Pvt. Ltd.)    0-5 Yrs  \n",
       "9                                 Fractal Analytics    3-7 Yrs  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Data Frame\n",
    "jobs= pd.DataFrame()\n",
    "jobs[\"Job_title\"]=job_title[:10]\n",
    "jobs[\"Job_Location\"]=loc[:10]\n",
    "jobs[\"Company_name\"]=company[:10]\n",
    "jobs[\"Experience\"]=experience[:10]\n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. You have to scrape company_name, No. of days ago when job was posted, Rating of the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. first get the webpage https://www.glassdoor.co.in/index.htm\n",
    "url=\"https://www.glassdoor.co.in/index.htm\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Search_btn= driver.find_element_by_xpath(\"/html/body/header/nav[1]/div/div/div/div[4]/div[1]/button/span\")\n",
    "Search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Enter “Data Scientist” in “Job Title,Keyword,Company” field and enter “Noida” in “location” field.\n",
    "search= driver.find_element_by_id(\"scKeyword\")\n",
    "search.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc= driver.find_element_by_id(\"scLocation\")\n",
    "loc.send_keys(\"Noida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on search button\n",
    "Search_btn= driver.find_element_by_xpath(\"/html/body/header/nav[1]/div/div/div/div[4]/div[3]/div[2]/form/div[2]/div[1]/button/span\")\n",
    "Search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BreathX Technologies Pvt Ltd, A Canary Global Inc. company',\n",
       " 'Kovid BioAnalytics',\n",
       " 'Applied Materials Inc.',\n",
       " 'OXO Solutions',\n",
       " 'Barclays',\n",
       " 'Siemens Technology and Services Private Limited',\n",
       " 'White Vectors',\n",
       " 'Applicate IT Solutions Pvt. Ltd.',\n",
       " 'Shell',\n",
       " 'BNY Mellon']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Then scrape the data for the first 10 jobs results you get in the above shown page.\n",
    "company_tags= driver.find_elements_by_xpath(\"//a[@class=' css-l2wjgv e1n63ojh0 jobLink']/span\")\n",
    "company_names=[]\n",
    "for i in company_tags:\n",
    "    company_names.append(i.text)\n",
    "company_names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9d', '1d', '30d+', '8d', '1d', '24h', '2d', '2d', '24h', '24h']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "days_tag= driver.find_elements_by_xpath(\"//div[@class='d-flex align-items-end pl-std css-mi55ob']\")\n",
    "days_before=[]\n",
    "for i in days_tag:\n",
    "    days_before.append(i.text)\n",
    "days_before[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Job_posted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BreathX Technologies Pvt Ltd, A Canary Global ...</td>\n",
       "      <td>9d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kovid BioAnalytics</td>\n",
       "      <td>1d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Applied Materials Inc.</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OXO Solutions</td>\n",
       "      <td>8d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barclays</td>\n",
       "      <td>1d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Siemens Technology and Services Private Limited</td>\n",
       "      <td>24h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>White Vectors</td>\n",
       "      <td>2d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Applicate IT Solutions Pvt. Ltd.</td>\n",
       "      <td>2d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shell</td>\n",
       "      <td>24h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BNY Mellon</td>\n",
       "      <td>24h</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Company_name Job_posted\n",
       "0  BreathX Technologies Pvt Ltd, A Canary Global ...         9d\n",
       "1                                 Kovid BioAnalytics         1d\n",
       "2                             Applied Materials Inc.       30d+\n",
       "3                                      OXO Solutions         8d\n",
       "4                                           Barclays         1d\n",
       "5    Siemens Technology and Services Private Limited        24h\n",
       "6                                      White Vectors         2d\n",
       "7                   Applicate IT Solutions Pvt. Ltd.         2d\n",
       "8                                              Shell        24h\n",
       "9                                         BNY Mellon        24h"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame\n",
    "jobs= pd.DataFrame()\n",
    "jobs[\"Company_name\"]=company_names[:10]\n",
    "jobs[\"Job_posted\"]=days_before[:10]\n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5: Write a python program to scrape the salary data for Data Scientist designation in Noida location.You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. first get the webpage https://www.glassdoor.co.in/Salaries/index.htm\n",
    "url=\"https://www.glassdoor.co.in/Salaries/index.htm\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Enter “Data Scientist” in Job title field and “Noida” in location field.\n",
    "search= driver.find_element_by_id(\"KeywordSearch\")\n",
    "search.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc= driver.find_element_by_id(\"LocationSearch\")\n",
    "loc.send_keys(\"Noida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Click the search button.\n",
    "Search_btn= driver.find_element_by_xpath(\"/html/body/div[3]/div/div[1]/div[1]/div/div/form/button\")\n",
    "Search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IBM',\n",
       " 'Tata Consultancy Services',\n",
       " 'Accenture',\n",
       " 'Delhivery',\n",
       " 'Ericsson-Worldwide',\n",
       " 'UnitedHealth Group',\n",
       " 'Valiance Solutions',\n",
       " 'EXL Service',\n",
       " 'Optum Global Solutions',\n",
       " 'ZS Associates']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Scrape data for first 10 companies. \n",
    "#Scrape the min salary, max salary, company name, Average salary and rating of the company.\n",
    "comp=driver.find_elements_by_xpath(\"//a[@class='css-f3vw95 e1aj7ssy3']\")\n",
    "company=[]\n",
    "for i in comp:\n",
    "    company.append(i.text)\n",
    "company[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Range: ₹6L - ₹27L',\n",
       " 'Range: ₹3L - ₹13L',\n",
       " 'Range: ₹6L - ₹22L',\n",
       " 'Range: ₹5L - ₹1Cr',\n",
       " 'Range: ₹4L - ₹16L',\n",
       " 'Range: ₹11L - ₹15L',\n",
       " 'Range: ₹5L - ₹15L',\n",
       " 'Range: ₹6L - ₹15L',\n",
       " 'Range: ₹4L - ₹22L',\n",
       " 'Range: ₹2L - ₹18L']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sal=driver.find_elements_by_xpath(\"//span[@class='d-block d-lg-none m-0 css-1b6bxoo']\")\n",
    "salary_range=[]\n",
    "for i in sal:\n",
    "    salary_range.append(i.text)\n",
    "salary_range[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['₹6L', '₹3L', '₹6L', '₹5L', '₹4L', '₹11', '₹5L', '₹6L', '₹4L', '₹2L']\n",
      "['₹27L', '₹13L', '₹22L', '₹1Cr', '₹16L', ' ₹15L', '₹15L', '₹15L', '₹22L', '₹18L']\n"
     ]
    }
   ],
   "source": [
    "min_sal=[]\n",
    "max_sal=[]\n",
    "for i in range(10):\n",
    "    s=salary_range[i]\n",
    "    min_sal.append(s[7:10])\n",
    "    max_sal.append(s[13:])\n",
    "print(min_sal)\n",
    "print(max_sal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹9,00,000  /yr',\n",
       " '₹6,15,289  /yr',\n",
       " '₹11,63,336  /yr',\n",
       " '₹12,18,244  /yr',\n",
       " '₹7,39,238  /yr',\n",
       " '₹13,19,140  /yr',\n",
       " '₹8,63,750  /yr',\n",
       " '₹11,10,000  /yr',\n",
       " '₹13,28,697  /yr',\n",
       " '₹11,42,356  /yr']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_sal=driver.find_elements_by_xpath(\"//div[@class='col-12 col-lg-4 px-lg-0 d-flex align-items-baseline']\")\n",
    "avg_salary=[]\n",
    "for i in avg_sal:\n",
    "    avg_salary.append(i.text.replace(\"\\n\",\" \"))\n",
    "avg_salary[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3.9 ★',\n",
       " '3.9 ★',\n",
       " '4 ★',\n",
       " '3.9 ★',\n",
       " '4 ★',\n",
       " '3.7 ★',\n",
       " '4.2 ★',\n",
       " '3.6 ★',\n",
       " '3.9 ★',\n",
       " '4 ★']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_=driver.find_elements_by_xpath(\"//div[@class='d-flex align-items-center mt-xxsm']\")\n",
    "rating=[]\n",
    "for i in rating_:\n",
    "    rating.append(i.text.replace(\"\\n\",\" \"))\n",
    "rating[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Min_Salary</th>\n",
       "      <th>Max_Salary</th>\n",
       "      <th>Average_Salary</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IBM</td>\n",
       "      <td>₹6L</td>\n",
       "      <td>₹27L</td>\n",
       "      <td>₹9,00,000  /yr</td>\n",
       "      <td>3.9 ★</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>₹3L</td>\n",
       "      <td>₹13L</td>\n",
       "      <td>₹6,15,289  /yr</td>\n",
       "      <td>3.9 ★</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>₹6L</td>\n",
       "      <td>₹22L</td>\n",
       "      <td>₹11,63,336  /yr</td>\n",
       "      <td>4 ★</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>₹5L</td>\n",
       "      <td>₹1Cr</td>\n",
       "      <td>₹12,18,244  /yr</td>\n",
       "      <td>3.9 ★</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>₹4L</td>\n",
       "      <td>₹16L</td>\n",
       "      <td>₹7,39,238  /yr</td>\n",
       "      <td>4 ★</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>₹11</td>\n",
       "      <td>₹15L</td>\n",
       "      <td>₹13,19,140  /yr</td>\n",
       "      <td>3.7 ★</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>₹5L</td>\n",
       "      <td>₹15L</td>\n",
       "      <td>₹8,63,750  /yr</td>\n",
       "      <td>4.2 ★</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EXL Service</td>\n",
       "      <td>₹6L</td>\n",
       "      <td>₹15L</td>\n",
       "      <td>₹11,10,000  /yr</td>\n",
       "      <td>3.6 ★</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Optum Global Solutions</td>\n",
       "      <td>₹4L</td>\n",
       "      <td>₹22L</td>\n",
       "      <td>₹13,28,697  /yr</td>\n",
       "      <td>3.9 ★</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>₹2L</td>\n",
       "      <td>₹18L</td>\n",
       "      <td>₹11,42,356  /yr</td>\n",
       "      <td>4 ★</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Company_name Min_Salary Max_Salary   Average_Salary Ratings\n",
       "0                        IBM        ₹6L       ₹27L   ₹9,00,000  /yr   3.9 ★\n",
       "1  Tata Consultancy Services        ₹3L       ₹13L   ₹6,15,289  /yr   3.9 ★\n",
       "2                  Accenture        ₹6L       ₹22L  ₹11,63,336  /yr     4 ★\n",
       "3                  Delhivery        ₹5L       ₹1Cr  ₹12,18,244  /yr   3.9 ★\n",
       "4         Ericsson-Worldwide        ₹4L       ₹16L   ₹7,39,238  /yr     4 ★\n",
       "5         UnitedHealth Group        ₹11       ₹15L  ₹13,19,140  /yr   3.7 ★\n",
       "6         Valiance Solutions        ₹5L       ₹15L   ₹8,63,750  /yr   4.2 ★\n",
       "7                EXL Service        ₹6L       ₹15L  ₹11,10,000  /yr   3.6 ★\n",
       "8     Optum Global Solutions        ₹4L       ₹22L  ₹13,28,697  /yr   3.9 ★\n",
       "9              ZS Associates        ₹2L       ₹18L  ₹11,42,356  /yr     4 ★"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame\n",
    "Salary_data= pd.DataFrame()\n",
    "Salary_data[\"Company_name\"]=company[:10]\n",
    "Salary_data[\"Min_Salary\"]=min_sal\n",
    "Salary_data[\"Max_Salary\"]=max_sal\n",
    "Salary_data[\"Average_Salary\"]=avg_salary[:10]\n",
    "Salary_data[\"Ratings\"]=rating[:10]\n",
    "Salary_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:( Brand, Product Description, Price, Discount %)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.flipkart.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and click the search icon\n",
    "search= driver.find_element_by_xpath(\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input\")\n",
    "search.send_keys(\"sunglasses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn= driver.find_element_by_xpath(\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_perc=[]\n",
    "brand=[]\n",
    "prod_desc=[]\n",
    "price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,4):\n",
    "    brand_tag= driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    for j in brand_tag: \n",
    "        brand.append(j.text.replace(\"\\n\",\" \"))      # extracting text\n",
    "        \n",
    "    desc_tag= driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "    for j in desc_tag:\n",
    "        prod_desc.append(j.text.replace(\"\\n\",\" \"))      # extracting text\n",
    "    \n",
    "    price_tags= driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "    for j in price_tags:\n",
    "        price.append(j.text.replace(\"\\n\",\" \"))        # extracting text\n",
    "    \n",
    "    disc_tags= driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\")\n",
    "    for j in disc_tags:\n",
    "        disc_perc.append(j.text.replace(\"\\n\",\" \"))       # extracting text\n",
    "    \n",
    "    nxt_button=driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")     #scraping the list of buttons from the page\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href'))       #getting the link from the list for next page\n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand_name</th>\n",
       "      <th>Product_Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount_Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Round Sunglasses (Free...</td>\n",
       "      <td>₹449</td>\n",
       "      <td>83% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Round Sunglasses (Free...</td>\n",
       "      <td>₹449</td>\n",
       "      <td>87% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹758</td>\n",
       "      <td>₹141 off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹513</td>\n",
       "      <td>₹286 off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kingsunglasses</td>\n",
       "      <td>Mirrored, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹299</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Brand_name                                Product_Description Price  \\\n",
       "0  ROZZETTA CRAFT  UV Protection, Gradient Round Sunglasses (Free...  ₹449   \n",
       "1  ROZZETTA CRAFT  UV Protection, Gradient Round Sunglasses (Free...  ₹449   \n",
       "2        Fastrack      UV Protection Wayfarer Sunglasses (Free Size)  ₹758   \n",
       "3        Fastrack   UV Protection Rectangular Sunglasses (Free Size)  ₹513   \n",
       "4  kingsunglasses  Mirrored, UV Protection Wayfarer Sunglasses (F...  ₹299   \n",
       "\n",
       "  Discount_Percentage  \n",
       "0             83% off  \n",
       "1             87% off  \n",
       "2            ₹141 off  \n",
       "3            ₹286 off  \n",
       "4             88% off  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating data frame\n",
    "Sunglasses= pd.DataFrame()\n",
    "Sunglasses[\"Brand_name\"]=brand[:100]\n",
    "Sunglasses[\"Product_Description\"]=prod_desc[:100]\n",
    "Sunglasses[\"Price\"]=price[:100]\n",
    "Sunglasses[\"Discount_Percentage\"]=disc_perc[:100]\n",
    "Sunglasses.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open url\n",
    "url=\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reviews= driver.find_element_by_xpath(\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div/div/div[5]/div/a/div/span\")\n",
    "all_reviews.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings=[]\n",
    "review_full=[]\n",
    "review_summary=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,12):\n",
    "    try:\n",
    "        rating= driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "        for i in rating:\n",
    "            ratings.append(i.text.replace(\"\\n\",\" \"))\n",
    "    except NoSuchElementException:\n",
    "        ratings.append(\"-\")\n",
    "    try:\n",
    "        review_short= driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "        for j in review_short:\n",
    "            review_summary.append(j.text.replace(\"\\n\",\" \"))\n",
    "    except NoSuchElementException:\n",
    "        review_summary.append(\"-\")\n",
    "    try:\n",
    "        review= driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\")\n",
    "        for j in review:\n",
    "            review_full.append(j.text.replace(\"\\n\",\" \"))\n",
    "    except NoSuchElementException:\n",
    "        review_full.append(\"-\")\n",
    "    nxt_button=driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")     #scraping the list of buttons from the page\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href'))       #getting the link from the list for next page\n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review_summary</th>\n",
       "      <th>Full_Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money  The iPhone 11 of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.  I’m am v...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rating     Review_summary                                        Full_Review\n",
       "0      5          Brilliant  The Best Phone for the Money  The iPhone 11 of...\n",
       "1      5   Perfect product!  Amazing phone with great cameras and better ba...\n",
       "2      5  Worth every penny  Previously I was using one plus 3t it was a gr...\n",
       "3      5          Fabulous!  This is my first iOS phone. I am very happy wi...\n",
       "4      5      Great product  Amazing Powerful and Durable Gadget.  I’m am v..."
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating data frame\n",
    "Reviews= pd.DataFrame()\n",
    "Reviews[\"Rating\"]=ratings[:100]\n",
    "Reviews[\"Review_summary\"]=review_summary[:100]\n",
    "Reviews[\"Full_Review\"]=review_full[:100]\n",
    "Reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field. ( Brand, Product Description, Price, discount %)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open url\n",
    "url=\"https://www.flipkart.com\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for \"sneakers\"\n",
    "search= driver.find_element_by_xpath(\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input\")\n",
    "search.send_keys(\"sneakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to click on search button\n",
    "search_btn= driver.find_element_by_xpath(\"/html/body/div/div/div[1]/div[1]/div[2]/div[2]/form/div/button\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "discount_perc=[]\n",
    "brand=[]\n",
    "prod_desc=[]\n",
    "price=[]\n",
    "urls=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping urls for each sneakers\n",
    "for i in range(1,4):\n",
    "    url_tags=driver.find_elements_by_xpath(\"//a[@class='_3bPFwb']\")\n",
    "    for j in url_tags:\n",
    "        urls.append(j.get_attribute(\"href\"))\n",
    "    nxt_button=driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")     #scraping the list of buttons from the page\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href'))       #getting the link from the list for next page\n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in urls[:100]:\n",
    "    driver.get(j)\n",
    "    try:    \n",
    "        brand_tag= driver.find_element_by_xpath(\"//span[@class='G6XhRU']\")  #scraping data from xpath\n",
    "        brand.append(brand_tag.text.replace(\"\\n\",\" \"))      \n",
    "    except:  \n",
    "        brand.append(\"-\")   # if xpath does not have data\n",
    "    \n",
    "    try:    \n",
    "        desc_tag= driver.find_element_by_xpath(\"//span[@class='B_NuCI']\")   #scraping data from xpath \n",
    "        prod_desc.append(desc_tag.text.replace(\"\\n\",\" \"))  \n",
    "    except:\n",
    "        prod_desc.append(\"-\")    # if xpath does not have data\n",
    "\n",
    "    try:\n",
    "        price_tag= driver.find_element_by_xpath(\"//div[@class='_30jeq3 _16Jk6d']\")   #scraping data from xpath\n",
    "        price.append(price_tag.text.replace(\"\\n\",\" \"))  \n",
    "    except:\n",
    "        price.append(\"-\")   # if xpath does not have data\n",
    "\n",
    "    try:\n",
    "        disc_tags= driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb _31Dcoz pZkvcx']/span\")   #scraping data from xpath\n",
    "        discount_perc.append(j.text.replace(\"\\n\",\" \"))\n",
    "    except:\n",
    "        discount_perc.append(\"-\")    # if xpath does not have data\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROCKFIELD</td>\n",
       "      <td>Sneakers For Men  (Multicolor)</td>\n",
       "      <td>₹474</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SHOEFLY</td>\n",
       "      <td>Combo Pack of 2 New Fashion Casual Loafers Sne...</td>\n",
       "      <td>₹478</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Casual Sneakers Shoes For Men Sneakers For Men...</td>\n",
       "      <td>₹379</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASTEROID</td>\n",
       "      <td>Original Luxury Branded Fashionable Men's Casu...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CALCADOS</td>\n",
       "      <td>Modern Trendy Shoes Combo pack of 4 Sneakers F...</td>\n",
       "      <td>₹748</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brand                                Product_Description Price  \\\n",
       "0     ROCKFIELD                      Sneakers For Men  (Multicolor)  ₹474   \n",
       "1       SHOEFLY   Combo Pack of 2 New Fashion Casual Loafers Sne...  ₹478   \n",
       "2  Robbie jones   Casual Sneakers Shoes For Men Sneakers For Men...  ₹379   \n",
       "3      ASTEROID   Original Luxury Branded Fashionable Men's Casu...  ₹499   \n",
       "4      CALCADOS   Modern Trendy Shoes Combo pack of 4 Sneakers F...  ₹748   \n",
       "\n",
       "  Discount_percentage  \n",
       "0                   -  \n",
       "1                   -  \n",
       "2                   -  \n",
       "3                   -  \n",
       "4                   -  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sneakers= pd.DataFrame()\n",
    "Sneakers[\"Brand\"]=brand\n",
    "Sneakers[\"Product_Description\"]=prod_desc\n",
    "Sneakers[\"Price\"]=price\n",
    "Sneakers[\"Discount_percentage\"]=discount_perc\n",
    "Sneakers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q9: Go to the link - https://www.myntra.com/shoes Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”, as shown in the below image. And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open url\n",
    "url=\"https://www.myntra.com/shoes\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting Colour\n",
    "color_selection= driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/div\")\n",
    "color_selection.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting Price Range\n",
    "filter_selection= driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/div\")\n",
    "filter_selection.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=[]\n",
    "prod_desc=[]\n",
    "price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Shoes Data\n",
    "for i in range(1,3):\n",
    "    try:    \n",
    "        brand_tag= driver.find_elements_by_xpath(\"//h3[@class='product-brand']\")  #scraping data from xpath\n",
    "        for j in brand_tag: \n",
    "            brand.append(j.text.replace(\"\\n\",\" \"))      \n",
    "    except NoSuchElementException:  \n",
    "        brand.append(\"-\")   # if xpath does not have data\n",
    "    \n",
    "    try:    \n",
    "        desc_tag= driver.find_elements_by_xpath(\"//h4[@class='product-product']\")   #scraping data from xpath\n",
    "        for j in desc_tag:\n",
    "            prod_desc.append(j.text.replace(\"\\n\",\" \"))  \n",
    "    except NoSuchElementException:\n",
    "        prod_desc.append(\"-\")    # if xpath does not have data\n",
    "    \n",
    "    try:\n",
    "        price_tags= driver.find_elements_by_xpath(\"//div[@class='product-price']\")   #scraping data from xpath\n",
    "        for j in price_tags:\n",
    "            price.append(j.text.replace(\"\\n\",\" \"))  \n",
    "    except NoSuchElementException:\n",
    "        price.append(\"-\")   # if xpath does not have data\n",
    "     \n",
    "    nxt_button=driver.find_elements_by_xpath(\"//a[@rel='next']\")     #scraping the list of buttons from the page\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href'))       #getting the link from the list for next page\n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Brand list:  100\n",
      "Length of Brand list:  100\n",
      "Length of Brand list:  100\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of Brand list: \",len(brand))\n",
    "print(\"Length of Brand list: \",len(price))\n",
    "print(\"Length of Brand list: \",len(prod_desc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product_Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Rs. 6999</td>\n",
       "      <td>Mesh Hybrid Fuego Running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Rs. 10295</td>\n",
       "      <td>Men AIR ZOOM Running Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Rs. 7195</td>\n",
       "      <td>Men ZOOM SPAN 3 Running Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Rs. 7195</td>\n",
       "      <td>Women SPEEDREP Training Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FORCLAZ By Decathlon</td>\n",
       "      <td>Rs. 6999</td>\n",
       "      <td>TREKKING 100 Boots</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Brand      Price            Product_Description\n",
       "0                  Puma   Rs. 6999      Mesh Hybrid Fuego Running\n",
       "1                  Nike  Rs. 10295     Men AIR ZOOM Running Shoes\n",
       "2                  Nike   Rs. 7195  Men ZOOM SPAN 3 Running Shoes\n",
       "3                  Nike   Rs. 7195  Women SPEEDREP Training Shoes\n",
       "4  FORCLAZ By Decathlon   Rs. 6999             TREKKING 100 Boots"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Dataframe\n",
    "Shoes= pd.DataFrame()\n",
    "Shoes[\"Brand\"]=brand[:100]\n",
    "Shoes[\"Price\"]=price[:100]\n",
    "Shoes[\"Product_Description\"]=prod_desc[:100]\n",
    "Shoes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q10: Go to webpage https://www.amazon.in/. Enter “Laptop” in the search field and then click the search icon.. Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” and scrape first 10 laptops data ( title, Ratings, Price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open url\n",
    "url=\"https://www.amazon.in/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for \"laptop\"\n",
    "search= driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input\")\n",
    "search.send_keys(\"laptop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to click on search button\n",
    "search_btn= driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting filter using loop\n",
    "filter_button= driver.find_elements_by_xpath(\"//span[@class='a-size-base a-color-base']\")\n",
    "for i in filter_button:\n",
    "    if i.text==\"Intel Core i7\":\n",
    "        i.click()\n",
    "        break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting CPU type filter by text xpath\n",
    "filter_selection= driver.find_element_by_xpath(\"//*[text()='Intel Core i9']\")\n",
    "filter_selection.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_tags=driver.find_elements_by_xpath(\"//a[@class='a-link-normal a-text-normal']\")\n",
    "urls=[]\n",
    "for i in url_tags:\n",
    "    urls.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "title=[]\n",
    "price=[]\n",
    "rating=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Data for laptops\n",
    "for i in urls[:10]:\n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        title_t=driver.find_element_by_xpath(\"//h1[@class='a-size-large a-spacing-none']\")\n",
    "        title.append(title_t.text)\n",
    "    except NoSuchElementException:\n",
    "        title.append(\"-\")\n",
    "    try:\n",
    "        rate= driver.find_element_by_xpath(\"//span[@class='a-size-medium a-color-base']\")\n",
    "        rating.append(rate.text)\n",
    "    except NoSuchElementException:\n",
    "        rating.append(\"-\")\n",
    "    try:\n",
    "        price_t=driver.find_element_by_xpath(\"//span[@class='a-size-medium a-color-price priceBlockBuyingPriceString']\")\n",
    "        price.append(price_t.text)\n",
    "    except NoSuchElementException:\n",
    "        price.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Price</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lenovo Legion 7 10th Gen Intel Core i7 15.6 in...</td>\n",
       "      <td>₹ 2,00,000.00</td>\n",
       "      <td>2.8 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dell Alienware m15(R3) 15.6-inch FHD Gaming La...</td>\n",
       "      <td>₹ 1,74,990.00</td>\n",
       "      <td>3.1 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo Legion Y540 Intel Core i7 9th Gen 15.6”...</td>\n",
       "      <td>₹ 69,990.00</td>\n",
       "      <td>4.3 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HP Pavilion (2021) Thin &amp; Light 11th Gen Core ...</td>\n",
       "      <td>₹ 84,990.00</td>\n",
       "      <td>4.5 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i7-1...</td>\n",
       "      <td>₹ 59,999.00</td>\n",
       "      <td>4.4 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dell 14 (2021) i7-1165G7 2in1 Touch Screen Lap...</td>\n",
       "      <td>₹ 92,630.00</td>\n",
       "      <td>4.6 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HP Pavilion Gaming 10th Gen Intel Core i7 Proc...</td>\n",
       "      <td>₹ 86,990.00</td>\n",
       "      <td>4.2 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lenovo Yoga 7 11th Gen Intel Core i7 14\" (35.5...</td>\n",
       "      <td>₹ 96,872.00</td>\n",
       "      <td>4.1 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HP Envy x360 Convertible Touchscreen 13.3-inch...</td>\n",
       "      <td>-</td>\n",
       "      <td>4.6 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dell Inspiron 5406 14\" FHD Touch Display 2in1 ...</td>\n",
       "      <td>-</td>\n",
       "      <td>3.8 out of 5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Brand          Price  \\\n",
       "0  Lenovo Legion 7 10th Gen Intel Core i7 15.6 in...  ₹ 2,00,000.00   \n",
       "1  Dell Alienware m15(R3) 15.6-inch FHD Gaming La...  ₹ 1,74,990.00   \n",
       "2  Lenovo Legion Y540 Intel Core i7 9th Gen 15.6”...    ₹ 69,990.00   \n",
       "3  HP Pavilion (2021) Thin & Light 11th Gen Core ...    ₹ 84,990.00   \n",
       "4  Mi Notebook Horizon Edition 14 Intel Core i7-1...    ₹ 59,999.00   \n",
       "5  Dell 14 (2021) i7-1165G7 2in1 Touch Screen Lap...    ₹ 92,630.00   \n",
       "6  HP Pavilion Gaming 10th Gen Intel Core i7 Proc...    ₹ 86,990.00   \n",
       "7  Lenovo Yoga 7 11th Gen Intel Core i7 14\" (35.5...    ₹ 96,872.00   \n",
       "8  HP Envy x360 Convertible Touchscreen 13.3-inch...              -   \n",
       "9  Dell Inspiron 5406 14\" FHD Touch Display 2in1 ...              -   \n",
       "\n",
       "        Ratings  \n",
       "0  2.8 out of 5  \n",
       "1  3.1 out of 5  \n",
       "2  4.3 out of 5  \n",
       "3  4.5 out of 5  \n",
       "4  4.4 out of 5  \n",
       "5  4.6 out of 5  \n",
       "6  4.2 out of 5  \n",
       "7  4.1 out of 5  \n",
       "8  4.6 out of 5  \n",
       "9  3.8 out of 5  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating Data Frame\n",
    "Laptop= pd.DataFrame()\n",
    "Laptop[\"Brand\"]=title\n",
    "Laptop[\"Price\"]=price\n",
    "Laptop[\"Ratings\"]=rating\n",
    "Laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
