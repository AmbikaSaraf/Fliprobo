{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Worksheet 4 on Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing Libraries\n",
    "\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver= webdriver.Chrome(r\"C:\\Users\\Rajeev\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Scrape the details of most viewed videos on YouTube from Wikipedia:\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos/\n",
    "You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping names of the video\n",
    "\n",
    "name=[]\n",
    "\n",
    "try:\n",
    "\n",
    "    names=driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[2]\")\n",
    "\n",
    "    for i in names:\n",
    "\n",
    "        name.append(i.text)\n",
    "\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "\n",
    "    name.append('No details available')\n",
    "\n",
    "except StaleElementReferenceException:#handling Stale element exception\n",
    "\n",
    "    name.append('No details available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping ranks of the video\n",
    "\n",
    "rank=[]\n",
    "\n",
    "try:\n",
    "\n",
    "    ranks=driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[1]\")\n",
    "\n",
    "    for i in ranks:\n",
    "\n",
    "        rank.append(i.text)\n",
    "\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "\n",
    "    rank.append('No details available')\n",
    "\n",
    "except StaleElementReferenceException:#handling Stale element exception\n",
    "\n",
    "    rank.append('No details available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping uploaders of the video\n",
    "\n",
    "artist=[]\n",
    "\n",
    "try:\n",
    "\n",
    "    uplod=driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[3]\")\n",
    "\n",
    "    for i in uplod:\n",
    "\n",
    "        artist.append(i.text)\n",
    "\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "\n",
    "    artist.append('No details available')\n",
    "\n",
    "except StaleElementReferenceException:#handling Stale element exception\n",
    "\n",
    "    artist.append('No details available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping views of the video\n",
    "\n",
    "views=[]\n",
    "\n",
    "try:\n",
    "\n",
    "    v=driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[4]\")\n",
    "\n",
    "    for i in v:\n",
    "\n",
    "        views.append(i.text)\n",
    "\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "\n",
    "    views.append('No details available')\n",
    "\n",
    "except StaleElementReferenceException:#handling Stale element exception\n",
    "\n",
    "    views.append('No details available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping date of upload of the video\n",
    "\n",
    "date=[]\n",
    "\n",
    "try:\n",
    "\n",
    "    dt=driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[5]\")\n",
    "\n",
    "    for i in dt:\n",
    "\n",
    "        date.append(i.text)\n",
    "\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "\n",
    "    date.append('No details available')\n",
    "\n",
    "except StaleElementReferenceException:#handling Stale element exception\n",
    "\n",
    "    date.append('No details available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Views</th>\n",
       "      <th>Upload_Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[22]</td>\n",
       "      <td>Pinkfong Kids' Songs &amp; Stories</td>\n",
       "      <td>9.04</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[24]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>7.46</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[25]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>5.58</td>\n",
       "      <td>October 8, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Shape of You\"[26]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>5.40</td>\n",
       "      <td>January 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"See You Again\"[27]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>5.19</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rank                        Name                          Artist Views  \\\n",
       "0   1.      \"Baby Shark Dance\"[22]  Pinkfong Kids' Songs & Stories  9.04   \n",
       "1   2.             \"Despacito\"[24]                      Luis Fonsi  7.46   \n",
       "2   3.  \"Johny Johny Yes Papa\"[25]                     LooLoo Kids  5.58   \n",
       "3   4.          \"Shape of You\"[26]                      Ed Sheeran  5.40   \n",
       "4   5.         \"See You Again\"[27]                     Wiz Khalifa  5.19   \n",
       "\n",
       "        Upload_Date  \n",
       "0     June 17, 2016  \n",
       "1  January 12, 2017  \n",
       "2   October 8, 2016  \n",
       "3  January 30, 2017  \n",
       "4     April 6, 2015  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the data frame\n",
    "Video_Details= pd.DataFrame()\n",
    "Video_Details[\"Rank\"]=rank\n",
    "Video_Details[\"Name\"]=name\n",
    "Video_Details[\"Artist\"]=artist\n",
    "Video_Details[\"Views\"]=views\n",
    "Video_Details[\"Upload_Date\"]=date\n",
    "Video_Details.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "\n",
    "A) Match title (I.e. 1st ODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.bcci.tv\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening desired page\n",
    "mnu_btn=driver.find_element_by_xpath(\"//button[@class='navigation__header-button menu-button js-navigation-menu-button']\")\n",
    "mnu_btn.click()\n",
    "\n",
    "drop=driver.find_element_by_xpath(\"//div[@class='navigation__link navigation__link--has-drop-down js-navigation-link']\")\n",
    "drop.click()\n",
    "\n",
    "slct=driver.find_element_by_xpath(\"/html/body/div[3]/div/div[2]/div[2]/nav/ul/li[1]/div[2]/div/ul/li[1]/a\")\n",
    "slct.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping match title\n",
    "title=[]\n",
    "try:\n",
    "    mt=driver.find_elements_by_xpath(\"//strong[@class='fixture__name fixture__name--with-margin']\")\n",
    "    \n",
    "    for i in mt:\n",
    "        title.append(i.text)\n",
    "        \n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    title.append(\"No Such Details\")\n",
    "    \n",
    "except StaleElemnetReferenceException:  #handling Stale element exception\n",
    "    title.append(\"No Such Details\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping series detail\n",
    "series=[]\n",
    "try:\n",
    "    ser=driver.find_elements_by_xpath(\"//span[@class='u-unskewed-text fixture__tournament-label u-truncated']\")\n",
    "    \n",
    "    for i in ser:\n",
    "        series.append(i.text)\n",
    "\n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    series.append(\"No Such Details\")\n",
    "    \n",
    "except StaleElemnetReferenceException:  #handling Stale element exception\n",
    "    series.append(\"No Such Details\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping place of match\n",
    "place=[]\n",
    "try:\n",
    "    plc_tag=driver.find_elements_by_xpath(\"//p[@class='fixture__additional-info']/span\")\n",
    "    \n",
    "    for i in plc_tag:\n",
    "        place.append(i.text)\n",
    "        \n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    place.append(\"No Such Details\")\n",
    "    \n",
    "except StaleElemnetReferenceException:  #handling Stale element exception\n",
    "    place.append(\"No Such Details\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping date of match\n",
    "date=[]\n",
    "try:\n",
    "    dt_tag=driver.find_elements_by_xpath(\"//span[@class='fixture__datetime tablet-only']/strong\")\n",
    "    \n",
    "    for i in dt_tag:\n",
    "        date.append(i.text)\n",
    "        \n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    date.append(\"No Such Details\")\n",
    "    \n",
    "except StaleElemnetReferenceException:  #handling Stale element exception\n",
    "    date.append(\"No Such Details\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping time of match\n",
    "time_t=[]\n",
    "try:\n",
    "    tm_tag=driver.find_elements_by_xpath(\"//span[@class='fixture__datetime tablet-only']\")\n",
    "    \n",
    "    for i in tm_tag:\n",
    "        time_t.append(i.text)\n",
    "        \n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    time_t.append(\"No Such Details\")\n",
    "    \n",
    "except StaleElemnetReferenceException:  #handling Stale element exception\n",
    "    time_t.append(\"No Such Details\")\n",
    "\n",
    "    # fetching time \n",
    "tym=[]\n",
    "for i in range(len(time_t)):\n",
    "    s=time_t[i]\n",
    "    tym.append(s[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1st Test</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>Trent Bridge, Nottingham</td>\n",
       "      <td>Wednesday 4 August</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2nd Test</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>Lord's, London</td>\n",
       "      <td>Thursday 12 August</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3rd Test</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>Headingley, Leeds</td>\n",
       "      <td>Wednesday 25 August</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4th Test</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>The Oval, London</td>\n",
       "      <td>Thursday 2 September</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5th Test</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>Old Trafford, Manchester</td>\n",
       "      <td>Friday 10 September</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Match title                Series                     Place  \\\n",
       "0    1st Test  ENGLAND V INDIA 2021  Trent Bridge, Nottingham   \n",
       "1    2nd Test  ENGLAND V INDIA 2021            Lord's, London   \n",
       "2    3rd Test  ENGLAND V INDIA 2021         Headingley, Leeds   \n",
       "3    4th Test  ENGLAND V INDIA 2021          The Oval, London   \n",
       "4    5th Test  ENGLAND V INDIA 2021  Old Trafford, Manchester   \n",
       "\n",
       "                   Date        Time  \n",
       "0    Wednesday 4 August   15:30 IST  \n",
       "1    Thursday 12 August   15:30 IST  \n",
       "2   Wednesday 25 August   15:30 IST  \n",
       "3  Thursday 2 September   15:30 IST  \n",
       "4   Friday 10 September   15:30 IST  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creating a dataframe\n",
    "International_Fixtures= pd.DataFrame()\n",
    "International_Fixtures[\"Match title\"]=title\n",
    "International_Fixtures[\"Series\"]=series\n",
    "International_Fixtures[\"Place\"]=place\n",
    "International_Fixtures[\"Date\"]=date\n",
    "International_Fixtures[\"Time\"]=tym\n",
    "International_Fixtures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape the details of selenium exception from guru99.com.\n",
    "Url = https://www.guru99.com/\n",
    "You need to find following details:\n",
    "A) Name\n",
    "B) Description\n",
    "Note: - From guru99 home page you have to reach to selenium exception handling page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.guru99.com\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_btn=driver.find_element_by_xpath(\"/html/body/div[2]/section[4]/div/div/div/div/div/div/div/div[1]/div/ul[1]/li[3]/a\")\n",
    "sel_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_excp=driver.find_element_by_xpath(\"/html/body/div[2]/section[3]/div/div[1]/main/div/div/div/div/div/div/div[2]/table[5]/tbody/tr[34]/td[1]/a\")\n",
    "sel_excp.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping name of exception\n",
    "name=[]\n",
    "\n",
    "try:\n",
    "    nm=driver.find_elements_by_xpath(\"//table[@class='table table-striped']/tbody/tr/td[1]\")\n",
    "    \n",
    "    for i in nm:\n",
    "        name.append(i.text)\n",
    "        \n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    name.append(\"No Such Details\")\n",
    "    \n",
    "except StaleElemnetReferenceException:  #handling Stale element exception\n",
    "    name.append(\"No Such Details\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping description of exception\n",
    "desc=[]\n",
    "\n",
    "try:\n",
    "    desc_tag=driver.find_elements_by_xpath(\"//table[@class='table table-striped']/tbody/tr/td[2]\")\n",
    "    \n",
    "    for i in desc_tag:\n",
    "        desc.append(i.text)\n",
    "        \n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    desc.append(\"No Such Details\")\n",
    "    \n",
    "except StaleElemnetReferenceException:  #handling Stale element exception\n",
    "    desc.append(\"No Such Details\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Exception name</td>\n",
       "      <td>Description</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ElementNotVisibleException</td>\n",
       "      <td>This type of Selenium exception occurs when an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ElementNotSelectableException</td>\n",
       "      <td>This Selenium exception occurs when an element...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NoSuchElementException</td>\n",
       "      <td>This Exception occurs if an element could not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NoSuchFrameException</td>\n",
       "      <td>This Exception occurs if the frame target to b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Name  \\\n",
       "0                 Exception name   \n",
       "1     ElementNotVisibleException   \n",
       "2  ElementNotSelectableException   \n",
       "3         NoSuchElementException   \n",
       "4           NoSuchFrameException   \n",
       "\n",
       "                                         Description  \n",
       "0                                        Description  \n",
       "1  This type of Selenium exception occurs when an...  \n",
       "2  This Selenium exception occurs when an element...  \n",
       "3  This Exception occurs if an element could not ...  \n",
       "4  This Exception occurs if the frame target to b...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creating Dataframe\n",
    "Exception=pd.DataFrame()\n",
    "Exception[\"Name\"]=name\n",
    "Exception[\"Description\"]=desc\n",
    "Exception.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP at current price (19-20)\n",
    "D) GSDP at current price (18-19)\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"http://statisticstimes.com\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop=driver.find_element_by_xpath(\"/html/body/div[2]/div[1]/div[2]/div[2]/button\")\n",
    "drop.click()\n",
    "\n",
    "btn=driver.find_element_by_xpath(\"/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]\")\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "stgdp_btn=driver.find_element_by_xpath(\"/html/body/div[2]/div[2]/div[2]/ul/li[1]/a\")\n",
    "stgdp_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scraping rank of state\n",
    "rank=[]\n",
    "try:\n",
    "    rnk=driver.find_elements_by_xpath(\"//tr[@role='row']/td[1]\")\n",
    "    for i in rnk:\n",
    "        rank.append(i.text)\n",
    "        \n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    rank.append(\"No Such Details\")\n",
    "    \n",
    "except StaleElemnetReferenceException:  #handling Stale element exception\n",
    "    rank.append(\"No Such Details\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping for state name\n",
    "state=[]\n",
    "try:\n",
    "    stt=driver.find_elements_by_xpath(\"//tr[@role='row']/td[2]\")\n",
    "    for i in stt:\n",
    "        state.append(i.text)\n",
    "        \n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    state.append(\"No Such Details\")\n",
    "    \n",
    "except StaleElemnetReferenceException:  #handling Stale element exception\n",
    "    state.append(\"No Such Details\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping for GSDP(19-20)\n",
    "gsdp_c1=[]\n",
    "try:\n",
    "    gsdp=driver.find_elements_by_xpath(\"//tr[@role='row']/td[3]\")\n",
    "    for i in gsdp:\n",
    "        gsdp_c1.append(i.text)\n",
    "        \n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    gsdp_c1.append(\"No Such Details\")\n",
    "    \n",
    "except StaleElemnetReferenceException:  #handling Stale element exception\n",
    "    gsdp_c1.append(\"No Such Details\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping for GSDP(18-19)\n",
    "gsdp_c2=[]\n",
    "try:\n",
    "    gsdp=driver.find_elements_by_xpath(\"//tr[@role='row']/td[4]\")\n",
    "    for i in gsdp:\n",
    "        gsdp_c2.append(i.text)\n",
    "        \n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    gsdp_c2.append(\"No Such Details\")\n",
    "    \n",
    "except StaleElemnetReferenceException:  #handling Stale element exception\n",
    "    gsdp_c2.append(\"No Such Details\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapig Share data for each state\n",
    "share=[]\n",
    "try:\n",
    "    shr=driver.find_elements_by_xpath(\"//tr[@role='row']/td[5]\")\n",
    "    for i in shr:\n",
    "        share.append(i.text)\n",
    "        \n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    share.append(\"No Such Details\")\n",
    "    \n",
    "except StaleElemnetReferenceException:  #handling Stale element exception\n",
    "    share.append(\"No Such Details\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping GDP for each state\n",
    "gdp=[]\n",
    "\n",
    "try:\n",
    "    gdp_t=driver.find_elements_by_xpath(\"//tr[@role='row']/td[6]\")\n",
    "    for i in gdp_t:\n",
    "        gdp.append(i.text)\n",
    "        \n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    gdp.append(\"No Such Details\")\n",
    "    \n",
    "except StaleElemnetReferenceException:  #handling Stale element exception\n",
    "    gdp.append(\"No Such Details\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP(19-20)</th>\n",
       "      <th>GSDP(18-19)</th>\n",
       "      <th>Share</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rank          State GSDP(19-20) GSDP(18-19)   Share      GDP\n",
       "0    1    Maharashtra           -   2,632,792  13.94%  399.921\n",
       "1    2     Tamil Nadu   1,845,853   1,630,208   8.63%  247.629\n",
       "2    3  Uttar Pradesh   1,687,818   1,584,764   8.39%  240.726\n",
       "3    4        Gujarat           -   1,502,899   7.96%  228.290\n",
       "4    5      Karnataka   1,631,977   1,493,127   7.91%  226.806"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Data frame\n",
    "GDP_statewise=pd.DataFrame()\n",
    "GDP_statewise[\"Rank\"]=rank\n",
    "GDP_statewise[\"State\"]=state\n",
    "GDP_statewise[\"GSDP(19-20)\"]=gsdp_c1\n",
    "GDP_statewise[\"GSDP(18-19)\"]=gsdp_c2\n",
    "GDP_statewise[\"Share\"]=share\n",
    "GDP_statewise[\"GDP\"]=gdp\n",
    "GDP_statewise.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used\n",
    "\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://github.com\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnu_btn=driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[1]/div[2]/button\")\n",
    "mnu_btn.click()\n",
    "\n",
    "exp_drp=driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/summary\")\n",
    "exp_drp.click()\n",
    "\n",
    "trnd_btn=driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/div/ul[2]/li[3]/a\")\n",
    "trnd_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=[]\n",
    "url_t=driver.find_elements_by_xpath(\"//h1[@class='h3 lh-condensed']/a\")\n",
    "for i in url_t:\n",
    "    url.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "desc=[]\n",
    "cont=[]\n",
    "lang=[]\n",
    "\n",
    "for i in (range(len(url))):\n",
    "    driver.get(url[i])\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Scraping name of repository\n",
    "    try:\n",
    "        nm=driver.find_element_by_xpath(\"//h1[@class=' d-flex flex-wrap flex-items-center break-word f3 text-normal']\")\n",
    "        name.append(nm.text)\n",
    "        \n",
    "    except NoSuchElementException:  #handling no such element exception\n",
    "        name.append(\"No Such Details\")\n",
    "    \n",
    "    except StaleElementReferenceException:  #handling Stale element exception\n",
    "        name.append(\"No Such Details\")\n",
    "        \n",
    "    # Scraping description of repository\n",
    "    try:\n",
    "        desc_t=driver.find_element_by_xpath(\"//p[@class='f4 mb-3']\")\n",
    "        desc.append(desc_t.text)\n",
    "        \n",
    "    except NoSuchElementException:  #handling no such element exception\n",
    "        desc.append(\"No Such Details\")\n",
    "    \n",
    "    except StaleElemnetReferenceException:  #handling Stale element exception\n",
    "        desc.append(\"No Such Details\")\n",
    "        \n",
    "        # Scraping contributers count in repository\n",
    "    try:\n",
    "        cont_t=driver.find_element_by_xpath(\"//div[@class='BorderGrid BorderGrid--spacious']/div[3]/div/h2/a/span\")\n",
    "        cont.append(cont_t.text)\n",
    "        \n",
    "    except NoSuchElementException:  #handling no such element exception\n",
    "        cont.append(\"No Such Details\")\n",
    "    \n",
    "    except StaleElemnetReferenceException:  #handling Stale element exception\n",
    "        cont.append(\"No Such Details\")\n",
    "\n",
    "        # Scraping language used in repository\n",
    "    try:\n",
    "        lng_t=driver.find_element_by_xpath(\"//div[@class='BorderGrid BorderGrid--spacious']/div[4]/div/ul\")\n",
    "        lang.append(lng_t.text)\n",
    "        \n",
    "    except NoSuchElementException:  #handling no such element exception\n",
    "        lang.append(\"No Such Details\")\n",
    "    \n",
    "    except StaleElemnetReferenceException:  #handling Stale element exception\n",
    "        lang.append(\"No Such Details\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Language</th>\n",
       "      <th>Contributers_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mitmproxy\\n/\\nmitmproxy</td>\n",
       "      <td>An interactive TLS-capable intercepting HTTP p...</td>\n",
       "      <td></td>\n",
       "      <td>1.4k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hiroshiba\\n/\\nvoicevox</td>\n",
       "      <td>No Such Details</td>\n",
       "      <td>Hiroshiba Hiroshiba\\nmasarakki masarakki\\nshir...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sysprog21\\n/\\nlkmpg</td>\n",
       "      <td>The Linux Kernel Module Programming Guide (upd...</td>\n",
       "      <td></td>\n",
       "      <td>No Such Details</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dataease\\n/\\ndataease</td>\n",
       "      <td>人人可用的开源数据可视化分析工具。</td>\n",
       "      <td>Java\\n40.6%\\nVue\\n26.9%\\nPLpgSQL\\n16.0%\\nJavaS...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>facebookresearch\\n/\\ndroidlet</td>\n",
       "      <td>A modular embodied agent architecture and plat...</td>\n",
       "      <td>No Such Details</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Name  \\\n",
       "0        mitmproxy\\n/\\nmitmproxy   \n",
       "1         Hiroshiba\\n/\\nvoicevox   \n",
       "2            sysprog21\\n/\\nlkmpg   \n",
       "3          dataease\\n/\\ndataease   \n",
       "4  facebookresearch\\n/\\ndroidlet   \n",
       "\n",
       "                                         Description  \\\n",
       "0  An interactive TLS-capable intercepting HTTP p...   \n",
       "1                                    No Such Details   \n",
       "2  The Linux Kernel Module Programming Guide (upd...   \n",
       "3                                  人人可用的开源数据可视化分析工具。   \n",
       "4  A modular embodied agent architecture and plat...   \n",
       "\n",
       "                                            Language Contributers_count  \n",
       "0                                                                  1.4k  \n",
       "1  Hiroshiba Hiroshiba\\nmasarakki masarakki\\nshir...                     \n",
       "2                                                       No Such Details  \n",
       "3  Java\\n40.6%\\nVue\\n26.9%\\nPLpgSQL\\n16.0%\\nJavaS...                  9  \n",
       "4                                    No Such Details                     "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame\n",
    "repository=pd.DataFrame()\n",
    "repository[\"Name\"]=name\n",
    "repository[\"Description\"]=desc\n",
    "repository[\"Language\"]=lang\n",
    "repository[\"Contributers_count\"]=cont\n",
    "repository.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Scrape the details of top 100 songs on billboard.com.\n",
    "Url = https://www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver= webdriver.Chrome(r\"C:\\Users\\Rajeev\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.billboard.com\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop= driver.find_element_by_xpath(\"/html/body/div[2]/div[2]/div[2]/nav/ul/li[3]/a\")\n",
    "drop.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Song name\n",
    "name=[]\n",
    "try:\n",
    "    nm=driver.find_elements_by_xpath(\"//span[@class='chart-element__information__song text--truncate color--primary']\")\n",
    "    for i in nm:\n",
    "        name.append(i.text)\n",
    "\n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    name.append(\"No Such Details\")\n",
    "    \n",
    "except StaleElementReferenceException:  #handling Stale element exception\n",
    "    name.append(\"No Such Details\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping song artist\n",
    "artst=[]\n",
    "try:\n",
    "    artst_tag=driver.find_elements_by_xpath(\"//span[@class='chart-element__information__artist text--truncate color--secondary']\")\n",
    "    for i in artst_tag:\n",
    "        artst.append(i.text)\n",
    "\n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    artst.append(\"No Such Details\")\n",
    "    \n",
    "except StaleElementReferenceException:  #handling Stale element exception\n",
    "    artst.append(\"No Such Details\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping rank of song last week\n",
    "lw=[]\n",
    "try:\n",
    "    lw_tag=driver.find_elements_by_xpath(\"//span[@class='chart-element__metas chart-element__metas--small display--flex']/span[1]\")\n",
    "    for i in lw_tag:\n",
    "        lw.append(i.text)\n",
    "\n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    lw.append(\"No Such Details\")\n",
    "    \n",
    "except StaleElementReferenceException:  #handling Stale element exception\n",
    "    lw.append(\"No Such Details\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping peak rank of song\n",
    "pk=[]\n",
    "try:\n",
    "    pk_tag=driver.find_elements_by_xpath(\"//span[@class='chart-element__metas chart-element__metas--small display--flex']/span[2]\")\n",
    "    for i in pk_tag:\n",
    "        pk.append(i.text)\n",
    "\n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    pk.append(\"No Such Details\")\n",
    "    \n",
    "except StaleElementReferenceException:  #handling Stale element exception\n",
    "    pk.append(\"No Such Details\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping for week on chart\n",
    "woc=[]\n",
    "try:\n",
    "    woc_tag=driver.find_elements_by_xpath(\"//span[@class='chart-element__metas chart-element__metas--small display--flex']/span[3]\")\n",
    "    for i in woc_tag:\n",
    "        woc.append(i.text)\n",
    "\n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    woc.append(\"No Such Details\")\n",
    "    \n",
    "except StaleElementReferenceException:  #handling Stale element exception\n",
    "    woc.append(\"No Such Details\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>LastWeek Rank</th>\n",
       "      <th>Peak Rank</th>\n",
       "      <th>Weeks on Chart</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Butter</td>\n",
       "      <td>BTS</td>\n",
       "      <td>1 LW</td>\n",
       "      <td>1 Pk</td>\n",
       "      <td>10 WoC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Industry Baby</td>\n",
       "      <td>Lil Nas X &amp; Jack Harlow</td>\n",
       "      <td></td>\n",
       "      <td>2 Pk</td>\n",
       "      <td>1 WoC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good 4 U</td>\n",
       "      <td>Olivia Rodrigo</td>\n",
       "      <td>2 LW</td>\n",
       "      <td>1 Pk</td>\n",
       "      <td>11 WoC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stay</td>\n",
       "      <td>The Kid LAROI &amp; Justin Bieber</td>\n",
       "      <td>4 LW</td>\n",
       "      <td>3 Pk</td>\n",
       "      <td>3 WoC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Levitating</td>\n",
       "      <td>Dua Lipa Featuring DaBaby</td>\n",
       "      <td>3 LW</td>\n",
       "      <td>2 Pk</td>\n",
       "      <td>43 WoC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Song Name                         Artist LastWeek Rank Peak Rank  \\\n",
       "0         Butter                            BTS          1 LW      1 Pk   \n",
       "1  Industry Baby        Lil Nas X & Jack Harlow                    2 Pk   \n",
       "2       Good 4 U                 Olivia Rodrigo          2 LW      1 Pk   \n",
       "3           Stay  The Kid LAROI & Justin Bieber          4 LW      3 Pk   \n",
       "4     Levitating      Dua Lipa Featuring DaBaby          3 LW      2 Pk   \n",
       "\n",
       "  Weeks on Chart  \n",
       "0         10 WoC  \n",
       "1          1 WoC  \n",
       "2         11 WoC  \n",
       "3          3 WoC  \n",
       "4         43 WoC  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creating a data frame\n",
    "Top100_songs=pd.DataFrame()\n",
    "Top100_songs[\"Song Name\"]=name\n",
    "Top100_songs[\"Artist\"]=artst\n",
    "Top100_songs[\"LastWeek Rank\"]=lw\n",
    "Top100_songs[\"Peak Rank\"]=pk\n",
    "Top100_songs[\"Weeks on Chart\"]=woc\n",
    "Top100_songs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Scrape the details of Data science recruiters from naukri.com.\n",
    "Url = https://www.naukri.com/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Designation\n",
    "C) Company\n",
    "D) Skills they hire for\n",
    "E) Location\n",
    "\n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and click on search. All this should be done through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.naukri.com\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pg=driver.find_element_by_xpath(\"/html/body/div[1]/div[1]/div/ul[1]/li[2]/a\")\n",
    "new_page=new_pg.get_attribute(\"href\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(new_page) # to open recruiters page\n",
    "time.sleep(2)\n",
    "\n",
    "search=driver.find_element_by_xpath(\"/html/body/div[2]/div[2]/div[1]/div[1]/form/div[1]/div/div[1]/div[1]/div[2]/input\")\n",
    "search.send_keys(\"Data Science\")\n",
    "\n",
    "btn=driver.find_element_by_id(\"qsbFormBtn\")\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls=[]\n",
    "url_t=driver.find_elements_by_xpath(\"//a[@class='ellipsis']\")\n",
    "for i in url_t:\n",
    "    urls.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "desg=[]\n",
    "comp_name=[]\n",
    "skills=[]\n",
    "loc=[]\n",
    "\n",
    "for i in (range(len(urls))):\n",
    "    driver.get(urls[i])\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # Scraping Recruiter's name\n",
    "    try:\n",
    "        nm=driver.find_element_by_xpath(\"//h1[@class='fl ellipsis wLimit hd']\")\n",
    "        name.append(nm.text)\n",
    "\n",
    "    except NoSuchElementException:  #handling no such element exception\n",
    "        name.append(\"No Such Details\")\n",
    "    \n",
    "    except StaleElementReferenceException:  #handling Stale element exception\n",
    "        name.append(\"No Such Details\")\n",
    "\n",
    "    # Scraping Designation of recruiter\n",
    "    try:\n",
    "        desg_t=driver.find_element_by_xpath(\"//div[@class='rFrame fl infoWrapper']\")\n",
    "        desg.append(desg_t.text)\n",
    "\n",
    "    except NoSuchElementException:  #handling no such element exception\n",
    "        desg.append(\"No Such Details\")\n",
    "    \n",
    "    except StaleElementReferenceException:  #handling Stale element exception\n",
    "        desg.append(\"No Such Details\")\n",
    "\n",
    "    # Scraping Company of recruiter\n",
    "    try:\n",
    "        comp=driver.find_element_by_xpath(\"//div[@class='rFrame fl infoWrapper']/div[4]\")\n",
    "        comp_name.append(comp.text)\n",
    "\n",
    "    except NoSuchElementException:  #handling no such element exception\n",
    "        comp_name.append(\"No Such Details\")\n",
    "    \n",
    "    except StaleElementReferenceException:  #handling Stale element exception\n",
    "        comp_name.append(\"No Such Details\")\n",
    "\n",
    "    # Scraping skills they hire for\n",
    "    try:\n",
    "        skl=driver.find_element_by_xpath(\"//div[@class='fl lPortn']/p\")\n",
    "        skills.append(skl.text)\n",
    "\n",
    "    except NoSuchElementException:  #handling no such element exception\n",
    "        skills.append(\"No Such Details\")\n",
    "    \n",
    "    except StaleElementReferenceException:  #handling Stale element exception\n",
    "        skills.append(\"No Such Details\")\n",
    "        \n",
    "    # Scraping location of recruiter\n",
    "    try:\n",
    "        loc_t=driver.find_element_by_xpath(\"//div[@class=''rFrame fl infoWrapper']/div[5]\")\n",
    "        loc.append(loc_t.text)\n",
    "    \n",
    "    except NoSuchElementException:  #handling no such element exception\n",
    "        loc.append(\"No Such Details\")\n",
    "    \n",
    "    except StaleElementReferenceException:  #handling Stale element exception\n",
    "        loc.append(\"No Such Details\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aakash Harit</td>\n",
       "      <td>Aakash Harit\\nHR Manager\\nData Science Network...</td>\n",
       "      <td>Data Science Network</td>\n",
       "      <td>No Such Details</td>\n",
       "      <td>Classic ASP Developer , Internet Marketing Pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Such Details</td>\n",
       "      <td>No Such Details</td>\n",
       "      <td>No Such Details</td>\n",
       "      <td>No Such Details</td>\n",
       "      <td>No Such Details</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shravan Kumar Gaddam</td>\n",
       "      <td>shravan Kumar Gaddam\\nCompany Recruiter\\nShore...</td>\n",
       "      <td>Shore Infotech India Pvt. Ltd</td>\n",
       "      <td>No Such Details</td>\n",
       "      <td>.Net , Java , Data Science , Linux Administrat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No Such Details</td>\n",
       "      <td>No Such Details</td>\n",
       "      <td>No Such Details</td>\n",
       "      <td>No Such Details</td>\n",
       "      <td>No Such Details</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>MARSIAN Technologies LLP\\nCompany HR\\nMARSIAN ...</td>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>No Such Details</td>\n",
       "      <td>Mid Level, Junior Level</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Name  \\\n",
       "0              Aakash Harit   \n",
       "1           No Such Details   \n",
       "2      shravan Kumar Gaddam   \n",
       "3           No Such Details   \n",
       "4  MARSIAN Technologies LLP   \n",
       "\n",
       "                                         Designation  \\\n",
       "0  Aakash Harit\\nHR Manager\\nData Science Network...   \n",
       "1                                    No Such Details   \n",
       "2  shravan Kumar Gaddam\\nCompany Recruiter\\nShore...   \n",
       "3                                    No Such Details   \n",
       "4  MARSIAN Technologies LLP\\nCompany HR\\nMARSIAN ...   \n",
       "\n",
       "                         Company         Location  \\\n",
       "0           Data Science Network  No Such Details   \n",
       "1                No Such Details  No Such Details   \n",
       "2  Shore Infotech India Pvt. Ltd  No Such Details   \n",
       "3                No Such Details  No Such Details   \n",
       "4       MARSIAN Technologies LLP  No Such Details   \n",
       "\n",
       "                                              Skills  \n",
       "0  Classic ASP Developer , Internet Marketing Pro...  \n",
       "1                                    No Such Details  \n",
       "2  .Net , Java , Data Science , Linux Administrat...  \n",
       "3                                    No Such Details  \n",
       "4                            Mid Level, Junior Level  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Data frame\n",
    "Recruiters=pd.DataFrame()\n",
    "Recruiters[\"Name\"]=name\n",
    "Recruiters[\"Designation\"]=desg\n",
    "Recruiters[\"Company\"]=comp_name\n",
    "Recruiters[\"Location\"]=loc\n",
    "Recruiters[\"Skills\"]=skills\n",
    "Recruiters.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Scrape the details of Highest selling novels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/\n",
    "You have to find the following details:\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "Url = \"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\"\n",
    "driver.get(Url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Book name\n",
    "name=[]\n",
    "try:\n",
    "    nm=driver.find_elements_by_xpath(\"//table[@class='in-article sortable']/tbody/tr/td[2]\")\n",
    "    for i in nm:\n",
    "        name.append(i.text)\n",
    "\n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    name.append(\"No Such Details\")\n",
    "    \n",
    "except StaleElementReferenceException:  #handling Stale element exception\n",
    "    name.append(\"No Such Details\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping author name\n",
    "author=[]\n",
    "try:\n",
    "    auth=driver.find_elements_by_xpath(\"//table[@class='in-article sortable']/tbody/tr/td[3]\")\n",
    "    for i in auth:\n",
    "        author.append(i.text)\n",
    "\n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    author.append(\"No Such Details\")\n",
    "    \n",
    "except StaleElementReferenceException:  #handling Stale element exception\n",
    "    author.append(\"No Such Details\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Volumes sold\n",
    "vol_sold=[]\n",
    "try:\n",
    "    vol=driver.find_elements_by_xpath(\"//table[@class='in-article sortable']/tbody/tr/td[4]\")\n",
    "    for i in vol:\n",
    "        vol_sold.append(i.text)\n",
    "\n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    vol_sold.append(\"No Such Details\")\n",
    "    \n",
    "except StaleElementReferenceException:  #handling Stale element exception\n",
    "    vol_sold.append(\"No Such Details\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Publisher name\n",
    "pub=[]\n",
    "try:\n",
    "    pub_t=driver.find_elements_by_xpath(\"//table[@class='in-article sortable']/tbody/tr/td[5]\")\n",
    "    for i in pub_t:\n",
    "        pub.append(i.text)\n",
    "\n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    pub.append(\"No Such Details\")\n",
    "    \n",
    "except StaleElementReferenceException:  #handling Stale element exception\n",
    "    pub.append(\"No Such Details\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping genre of book\n",
    "gnr=[]\n",
    "try:\n",
    "    gnr_t=driver.find_elements_by_xpath(\"//table[@class='in-article sortable']/tbody/tr/td[6]\")\n",
    "    for i in gnr_t:\n",
    "        gnr.append(i.text)\n",
    "\n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    gnr.append(\"No Such Details\")\n",
    "    \n",
    "except StaleElementReferenceException:  #handling Stale element exception\n",
    "    gnr.append(\"No Such Details\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book_Name</th>\n",
       "      <th>Author</th>\n",
       "      <th>Volume Sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Book_Name         Author Volume Sold  \\\n",
       "0                          Da Vinci Code,The     Brown, Dan   5,094,805   \n",
       "1       Harry Potter and the Deathly Hallows  Rowling, J.K.   4,475,152   \n",
       "2   Harry Potter and the Philosopher's Stone  Rowling, J.K.   4,200,654   \n",
       "3  Harry Potter and the Order of the Phoenix  Rowling, J.K.   4,179,479   \n",
       "4                       Fifty Shades of Grey   James, E. L.   3,758,936   \n",
       "\n",
       "      Publisher                        Genre  \n",
       "0    Transworld  Crime, Thriller & Adventure  \n",
       "1    Bloomsbury           Children's Fiction  \n",
       "2    Bloomsbury           Children's Fiction  \n",
       "3    Bloomsbury           Children's Fiction  \n",
       "4  Random House              Romance & Sagas  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Data Frame\n",
    "Books_Sold=pd.DataFrame()\n",
    "Books_Sold[\"Book_Name\"]=name\n",
    "Books_Sold[\"Author\"]=author\n",
    "Books_Sold[\"Volume Sold\"]=vol_sold\n",
    "Books_Sold[\"Publisher\"]=pub\n",
    "Books_Sold[\"Genre\"]=gnr\n",
    "Books_Sold.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.imdb.com/list/ls095964455\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping TV Show name\n",
    "name=[]\n",
    "try:\n",
    "    nm=driver.find_elements_by_xpath(\"//h3[@class='lister-item-header']/a\")\n",
    "    for i in nm:\n",
    "        name.append(i.text)\n",
    "\n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    name.append(\"No Such Details\")\n",
    "    \n",
    "except StaleElementReferenceException:  #handling Stale element exception\n",
    "    name.append(\"No Such Details\")\n",
    "\n",
    "# Scraping span time of Tv show\n",
    "spn_tm=[]\n",
    "try:\n",
    "    spn=driver.find_elements_by_xpath(\"//h3[@class='lister-item-header']/span[2]\")\n",
    "    for i in spn:\n",
    "        spn_tm.append(i.text)\n",
    "\n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    spn_tm.append(\"No Such Details\")\n",
    "    \n",
    "except StaleElementReferenceException:  #handling Stale element exception\n",
    "    spn_tm.append(\"No Such Details\")\n",
    "\n",
    "# Scraping genre of book\n",
    "gnr=[]\n",
    "try:\n",
    "    gnr_t=driver.find_elements_by_xpath(\"//span[@class='genre']\")\n",
    "    for i in gnr_t:\n",
    "        gnr.append(i.text)\n",
    "\n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    gnr.append(\"No Such Details\")\n",
    "    \n",
    "except StaleElementReferenceException:  #handling Stale element exception\n",
    "    gnr.append(\"No Such Details\")\n",
    "\n",
    "# Scraping runtime of TV Show\n",
    "rntm=[]\n",
    "try:\n",
    "    rntm_t=driver.find_elements_by_xpath(\"//span[@class='runtime']\")\n",
    "    for i in rntm_t:\n",
    "        rntm.append(i.text)\n",
    "\n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    rntm.append(\"No Such Details\")\n",
    "    \n",
    "except StaleElementReferenceException:  #handling Stale element exception\n",
    "    rntm.append(\"No Such Details\")\n",
    "\n",
    "# Scraping rating of TV Show\n",
    "rtng=[]\n",
    "try:\n",
    "    rt=driver.find_elements_by_xpath(\"//div[@class='ipl-rating-widget']/div/span[2]\")\n",
    "    for i in rt:\n",
    "        rtng.append(i.text)\n",
    "\n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    rtng.append(\"No Such Details\")\n",
    "    \n",
    "except StaleElementReferenceException:  #handling Stale element exception\n",
    "    rtng.append(\"No Such Details\")\n",
    "\n",
    "# Scraping number of votes\n",
    "votes=[]\n",
    "try:\n",
    "    vt=driver.find_elements_by_xpath(\"//div[@class='lister-item-content']/p[4]/span[2]\")\n",
    "    for i in vt:\n",
    "        votes.append(i.text)\n",
    "\n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    votes.append(\"No Such Details\")\n",
    "    \n",
    "except StaleElementReferenceException:  #handling Stale element exception\n",
    "    votes.append(\"No Such Details\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Span Time</th>\n",
       "      <th>Genre</th>\n",
       "      <th>RunTime</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Number_of_votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1,848,399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>885,910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.2</td>\n",
       "      <td>885,834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>266,405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>226,968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name    Span Time                     Genre RunTime Ratings  \\\n",
       "0   Game of Thrones  (2011–2019)  Action, Adventure, Drama  57 min     9.2   \n",
       "1   Stranger Things     (2016– )    Drama, Fantasy, Horror  51 min     8.7   \n",
       "2  The Walking Dead  (2010–2022)   Drama, Horror, Thriller  44 min     8.2   \n",
       "3    13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller  60 min     7.6   \n",
       "4           The 100  (2014–2020)    Drama, Mystery, Sci-Fi  43 min     7.6   \n",
       "\n",
       "  Number_of_votes  \n",
       "0       1,848,399  \n",
       "1         885,910  \n",
       "2         885,834  \n",
       "3         266,405  \n",
       "4         226,968  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Dataframe\n",
    "TV_Shows=pd.DataFrame()\n",
    "TV_Shows[\"Name\"]=name\n",
    "TV_Shows[\"Span Time\"]=spn_tm\n",
    "TV_Shows[\"Genre\"]=gnr\n",
    "TV_Shows[\"RunTime\"]=rntm\n",
    "TV_Shows[\"Ratings\"]=rtng\n",
    "TV_Shows[\"Number_of_votes\"]=votes\n",
    "TV_Shows.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute\n",
    "G) Year\n",
    "\n",
    "Note: - from the home page you have to go to the Show All Dataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Url = \"https://archive.ics.uci.edu\"\n",
    "driver.get(Url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "btn=driver.find_element_by_xpath(\"/html/body/table[2]/tbody/tr/td/span/b/a\")\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping name of datasets\n",
    "name=[]\n",
    "try:\n",
    "    nm=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[2]\")\n",
    "    for i in nm:\n",
    "        name.append(i.text)\n",
    "\n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    name.append(\"No Such Details\")\n",
    "    \n",
    "except StaleElementReferenceException:  #handling Stale element exception\n",
    "    name.append(\"No Such Details\")\n",
    "\n",
    "# Scraping Data types\n",
    "type_=[]\n",
    "try:\n",
    "    typ=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[2]\")\n",
    "    for i in typ:\n",
    "        type_.append(i.text)\n",
    "\n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    type_.append(\"No Such Details\")\n",
    "    \n",
    "except StaleElementReferenceException:  #handling Stale element exception\n",
    "    type_.append(\"No Such Details\")\n",
    "\n",
    "# Scraping default task\n",
    "task=[]\n",
    "try:\n",
    "    tsk=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[3]\")\n",
    "    for i in tsk:\n",
    "        task.append(i.text)\n",
    "\n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    task.append(\"No Such Details\")\n",
    "    \n",
    "except StaleElementReferenceException:  #handling Stale element exception\n",
    "    task.append(\"No Such Details\")\n",
    "\n",
    "# Scraping type of attributes\n",
    "type_attr=[]\n",
    "try:\n",
    "    typ_attr=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[4]\")\n",
    "    for i in typ_attr:\n",
    "        type_attr.append(i.text)\n",
    "\n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    type_attr.append(\"No Such Details\")\n",
    "    \n",
    "except StaleElementReferenceException:  #handling Stale element exception\n",
    "    type_attr.append(\"No Such Details\")\n",
    "\n",
    "# Scraping Number of instances\n",
    "inst=[]\n",
    "try:\n",
    "    inst_t=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[5]\")\n",
    "    for i in inst_t:\n",
    "        inst.append(i.text)\n",
    "\n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    inst.append(\"No Such Details\")\n",
    "    \n",
    "except StaleElementReferenceException:  #handling Stale element exception\n",
    "    inst.append(\"No Such Details\")\n",
    "\n",
    "# Scraping Number of attributes\n",
    "attr=[]\n",
    "try:\n",
    "    attr_t=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[6]\")\n",
    "    for i in attr_t:\n",
    "        attr.append(i.text)\n",
    "\n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    attr.append(\"No Such Details\")\n",
    "    \n",
    "except StaleElementReferenceException:  #handling Stale element exception\n",
    "    attr.append(\"No Such Details\")\n",
    "\n",
    "# Scraping year \n",
    "year=[]\n",
    "try:\n",
    "    yr=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[7]\")\n",
    "    for i in yr:\n",
    "        year.append(i.text)\n",
    "\n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    year.append(\"No Such Details\")\n",
    "    \n",
    "except StaleElementReferenceException:  #handling Stale element exception\n",
    "    year.append(\"No Such Details\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Default task</th>\n",
       "      <th>Attribute type</th>\n",
       "      <th>Number of instances</th>\n",
       "      <th>Number of attributes</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Types</td>\n",
       "      <td>Data Types</td>\n",
       "      <td>Default Task</td>\n",
       "      <td>Attribute Types</td>\n",
       "      <td># Instances</td>\n",
       "      <td># Attributes</td>\n",
       "      <td>Year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name      Data Type          Default task  \\\n",
       "0     Data Types     Data Types          Default Task   \n",
       "1  Multivariate   Multivariate        Classification    \n",
       "2  Multivariate   Multivariate        Classification    \n",
       "3  Multivariate   Multivariate        Classification    \n",
       "4                                Recommender-Systems    \n",
       "\n",
       "                Attribute type Number of instances Number of attributes   Year  \n",
       "0              Attribute Types         # Instances         # Attributes   Year  \n",
       "1  Categorical, Integer, Real                4177                    8   1995   \n",
       "2        Categorical, Integer               48842                   14   1996   \n",
       "3  Categorical, Integer, Real                 798                   38          \n",
       "4                 Categorical               37711                  294   1998   "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creating dataframe\n",
    "DataSets=pd.DataFrame()\n",
    "DataSets[\"Name\"]=name\n",
    "DataSets[\"Data Type\"]=type_\n",
    "DataSets[\"Default task\"]=task\n",
    "DataSets[\"Attribute type\"]=type_attr\n",
    "DataSets[\"Number of instances\"]=inst\n",
    "DataSets[\"Number of attributes\"]=attr\n",
    "DataSets[\"Year\"]=year\n",
    "DataSets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
